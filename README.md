---
title: README
emoji: 👁
colorFrom: pink
colorTo: indigo
sdk: static
pinned: false
---

This organization is a part of the NeurIPS 2021 demonstration <a href="https://training-transformers-together.github.io/">"Training Transformers Together"</a>.

In this demo, we train a model similar to <a target="_blank" href="https://openai.com/blog/dall-e/">OpenAI DALL-E</a> —
a Transformer "language model" that generates images from text descriptions.
It is trained on <a target="_blank" href="https://laion.ai/laion-400-open-dataset/">LAION-400M</a>,
the world's largest openly available image-text-pair dataset with 400 million samples. Our model is based on
the <a target="_blank" href="https://github.com/lucidrains/DALLE-pytorch">dalle‑pytorch</a> implementation
by <a target="_blank" href="https://github.com/lucidrains">Phil Wang</a> with a few tweaks to make it communication-efficient.

See details about how to join and how it works on <a target="_blank" href="https://training-transformers-together.github.io/">our website</a>.

The organization gathers people participating in the collaborative training and provides links to the necessary resources:

- 👉 Starter kits for **Google Colab** and **Kaggle** (easy way to join the training)
- 👉 [Dashboard](https://huggingface.co/spaces/training-transformers-together/Dashboard) (the current training state: loss, number of peers, etc.)
- 👉 [Model](https://huggingface.co/training-transformers-together/dalle-demo) (the latest model checkpoint)
- 👉 [Dataset](https://huggingface.co/datasets/laion/laion_100m_vqgan_f8)

Feel free to reach us on [Discord](https://discord.gg/uGugx9zYvN) if you have any questions 🙂
